{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8dace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e70fc1d3c554c2182799b495a07e75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Test X', max=3.0, min=-3.0), FloatSlider(value=0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Generate some 2D data\n",
    "np.random.seed(42)\n",
    "class_0 = np.random.randn(10, 2) - 1\n",
    "class_1 = np.random.randn(10, 2) + 1\n",
    "\n",
    "X = np.vstack((class_0, class_1))\n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "# Fit KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Plotting function\n",
    "def plot_knn(test_x, test_y):\n",
    "    test_point = np.array([[test_x, test_y]])\n",
    "    pred = knn.predict(test_point)[0]\n",
    "    neighbors = knn.kneighbors(test_point, return_distance=False)[0]\n",
    "    \n",
    "    plt.figure(figsize=(7, 7))\n",
    "    \n",
    "    # Plot original data\n",
    "    plt.scatter(class_0[:, 0], class_0[:, 1], color='blue', label='Class 0')\n",
    "    plt.scatter(class_1[:, 0], class_1[:, 1], color='green', label='Class 1')\n",
    "\n",
    "    # Plot test point\n",
    "    color = 'blue' if pred == 0 else 'green'\n",
    "    plt.scatter(test_x, test_y, c=color, edgecolor='black', s=200, label='Test Point')\n",
    "    \n",
    "    # Highlight neighbors\n",
    "    for i in neighbors:\n",
    "        plt.plot([test_x, X[i, 0]], [test_y, X[i, 1]], 'k--', alpha=0.6)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f\"KNN Classification (K=2) — Predicted Class: {pred}\")\n",
    "    plt.grid(True)\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive controls\n",
    "interact(plot_knn,\n",
    "         test_x=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test X'),\n",
    "         test_y=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test Y'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c77a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68a5171c5c04fb89dde6c8a7219056f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Test X', max=3.0, min=-3.0), FloatSlider(value=0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Generate synthetic 2D data\n",
    "np.random.seed(42)\n",
    "class_0 = np.random.randn(10, 2) - 1\n",
    "class_1 = np.random.randn(10, 2) + 1\n",
    "\n",
    "X = np.vstack((class_0, class_1))\n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "# Fit Decision Tree Classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Plotting function with boundaries\n",
    "def plot_decision_tree_with_boundaries(test_x, test_y):\n",
    "    test_point = np.array([[test_x, test_y]])\n",
    "    pred = tree.predict(test_point)[0]\n",
    "\n",
    "    # Create a grid to plot decision boundaries\n",
    "    x_min, x_max = -4, 4\n",
    "    y_min, y_max = -4, 4\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot decision boundary\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
    "\n",
    "    # Plot data points\n",
    "    plt.scatter(class_0[:, 0], class_0[:, 1], color='blue', label='Class 0')\n",
    "    plt.scatter(class_1[:, 0], class_1[:, 1], color='green', label='Class 1')\n",
    "\n",
    "    # Plot test point\n",
    "    color = 'blue' if pred == 0 else 'green'\n",
    "    plt.scatter(test_x, test_y, color=color, edgecolor='black', s=200, label='Test Point')\n",
    "\n",
    "    plt.title(f\"Decision Tree with Boundaries — Predicted Class: {pred}\")\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive slider for test point\n",
    "interact(plot_decision_tree_with_boundaries,\n",
    "         test_x=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test X'),\n",
    "         test_y=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test Y'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f3d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314ba31bd60f40b8b08c5a06206386a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Test X', max=3.0, min=-3.0), FloatSlider(value=0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Perceptron\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Generate synthetic data (2 classes, linearly separable)\n",
    "np.random.seed(42)\n",
    "class_0 = np.random.randn(10, 2) - 1\n",
    "class_1 = np.random.randn(10, 2) + 1\n",
    "\n",
    "X = np.vstack((class_0, class_1))\n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "# Track loss during training\n",
    "loss_history = []\n",
    "model = Perceptron(max_iter=1, warm_start=True, tol=None, eta0=0.1, random_state=0)\n",
    "\n",
    "# Run step-by-step training manually to record losses\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    loss = np.sum(y_pred != y)  # Number of misclassified points\n",
    "    loss_history.append(loss)\n",
    "\n",
    "# Plotting function with decision boundaries and loss\n",
    "def plot_perceptron_with_boundaries(test_x, test_y):\n",
    "    test_point = np.array([[test_x, test_y]])\n",
    "    pred = model.predict(test_point)[0]\n",
    "\n",
    "    # Decision boundary grid\n",
    "    x_min, x_max = -4, 4\n",
    "    y_min, y_max = -4, 4\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot 1: decision boundary\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
    "    plt.scatter(class_0[:, 0], class_0[:, 1], color='blue', label='Class 0')\n",
    "    plt.scatter(class_1[:, 0], class_1[:, 1], color='green', label='Class 1')\n",
    "\n",
    "    color = 'blue' if pred == 0 else 'green'\n",
    "    plt.scatter(test_x, test_y, color=color, edgecolor='black', s=200, label='Test Point')\n",
    "    plt.title(f\"Perceptron Decision Boundary — Predicted Class: {pred}\")\n",
    "    plt.xlabel(\"X1\")\n",
    "    plt.ylabel(\"X2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    # Plot 2: loss per epoch\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), loss_history, marker='o')\n",
    "    plt.title(\"Perceptron Training Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Misclassified Points\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive test point selection\n",
    "interact(plot_perceptron_with_boundaries,\n",
    "         test_x=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test X'),\n",
    "         test_y=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test Y'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46daa526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adc7aa774884d039c49e3be9263bc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='x_point', max=4.0, min=-4.0), Output()), _dom_classe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Function and its derivative\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def df(x):\n",
    "    return 2*x\n",
    "\n",
    "# Plotting function\n",
    "def plot_gradient(x_point):\n",
    "    x = np.linspace(-5, 5, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    # Tangent line at x_point\n",
    "    slope = df(x_point)\n",
    "    tangent_line = slope * (x - x_point) + f(x_point)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, y, label='f(x) = x²')\n",
    "    plt.plot(x, tangent_line, '--', label=f'Tangent at x={x_point}')\n",
    "    plt.scatter(x_point, f(x_point), color='red', zorder=5)\n",
    "    plt.title(f'Gradient at x = {x_point} is {slope}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.axhline(0, color='gray', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive slider\n",
    "interact(plot_gradient, x_point=widgets.FloatSlider(value=2.0, min=-4, max=4, step=0.1));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee40547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa05b9400f42fc84bbbba4579c71d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=4.0, description='Start x', max=5.0, min=-5.0), FloatSlider(value=0.1,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "\n",
    "# Function and gradient\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def df(x):\n",
    "    return 2*x\n",
    "\n",
    "# Gradient descent step function\n",
    "def gradient_descent(start, learning_rate, steps):\n",
    "    x_vals = [start]\n",
    "    for _ in range(steps):\n",
    "        grad = df(x_vals[-1])\n",
    "        x_new = x_vals[-1] - learning_rate * grad\n",
    "        x_vals.append(x_new)\n",
    "    return x_vals, [f(x) for x in x_vals]\n",
    "\n",
    "# Plotting function\n",
    "def plot_descent(start, learning_rate, steps):\n",
    "    x = np.linspace(-5, 5, 400)\n",
    "    y = f(x)\n",
    "\n",
    "    x_path, y_path = gradient_descent(start, learning_rate, steps)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, y, label='f(x) = x²')\n",
    "    plt.plot(x_path, y_path, 'ro-', label='Descent path')\n",
    "    plt.title('Gradient Descent')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.axhline(0, color='gray', lw=0.5)\n",
    "    plt.axvline(0, color='gray', lw=0.5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "interact(\n",
    "    plot_descent,\n",
    "    start=FloatSlider(value=4.0, min=-5.0, max=5.0, step=0.1, description='Start x'),\n",
    "    learning_rate=FloatSlider(value=0.1, min=0.01, max=1.0, step=0.01, description='Learning rate'),\n",
    "    steps=IntSlider(value=10, min=1, max=50, step=1, description='Steps')\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74be70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b2570b46f64278a831e4ba2f8271fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=5.0, description='Test X', max=10.0), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Generate 1D linear data with noise\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 20).reshape(-1, 1)\n",
    "y = 3 * X.squeeze() + 4 + np.random.randn(20) * 2\n",
    "\n",
    "# Fit model with manual steps and track loss\n",
    "model = SGDRegressor(max_iter=1, eta0=0.01, learning_rate='constant',\n",
    "                     warm_start=True, random_state=42, tol=None)\n",
    "\n",
    "loss_history = []\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    loss = mean_squared_error(y, y_pred)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "# Plotting function\n",
    "def plot_linear_regression(test_x):\n",
    "    test_y = model.predict([[test_x]])[0]\n",
    "\n",
    "    # Plot 1: regression line and test point\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X, y, label=\"Data\", color='blue')\n",
    "    x_line = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "    y_line = model.predict(x_line)\n",
    "    plt.plot(x_line, y_line, color='red', label='Fitted Line')\n",
    "    plt.scatter(test_x, test_y, color='green', s=200, edgecolor='black', label=f\"Predicted Y: {test_y:.2f}\")\n",
    "    plt.title(\"Linear Regression Prediction\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 2: training loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), loss_history, marker='o')\n",
    "    plt.title(\"Training Loss (MSE) per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive slider for test input\n",
    "interact(plot_linear_regression,\n",
    "         test_x=FloatSlider(min=0, max=10, step=0.1, value=5, description='Test X'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9424301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd5ce2778f14d108a194cc1896b935d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='Degree', max=10, min=1), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "# Improved data: X not evenly spaced, more real-world like\n",
    "np.random.seed(42)\n",
    "X = np.random.uniform(-3, 3, 30).reshape(-1, 1)\n",
    "true_y = 0.5 * X.squeeze()**3 - X.squeeze()**2 + 2 * X.squeeze()\n",
    "y = true_y + np.random.randn(30) * 3  # Add noise\n",
    "\n",
    "# Main function\n",
    "def plot_polynomial_regression(degree, test_x):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    # SGDRegressor to simulate iterative learning\n",
    "    model = SGDRegressor(max_iter=1, eta0=0.01, learning_rate='constant',\n",
    "                         warm_start=True, random_state=42, tol=None)\n",
    "\n",
    "    loss_history = []\n",
    "    epochs = 100\n",
    "    for _ in range(epochs):\n",
    "        model.fit(X_poly, y)\n",
    "        y_pred = model.predict(X_poly)\n",
    "        loss = mean_squared_error(y, y_pred)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    # Predict for interactive test point\n",
    "    test_x_poly = poly.transform([[test_x]])\n",
    "    test_y = model.predict(test_x_poly)[0]\n",
    "\n",
    "    # Plot 1: Fit and test point\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X, y, color='blue', label='Data')\n",
    "    \n",
    "    x_range = np.linspace(-3.5, 3.5, 300).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_curve = model.predict(x_range_poly)\n",
    "    plt.plot(x_range, y_curve, color='red', label=f'Polynomial Degree {degree}')\n",
    "    \n",
    "    plt.scatter(test_x, test_y, color='green', edgecolor='black', s=200, label=f\"Predicted Y: {test_y:.2f}\")\n",
    "    plt.title(\"Polynomial Regression Fit\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 2: Loss per epoch\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), loss_history, marker='o')\n",
    "    plt.title(\"Training Loss (MSE) per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive controls\n",
    "interact(plot_polynomial_regression,\n",
    "         degree=IntSlider(min=1, max=10, step=1, value=3, description='Degree'),\n",
    "         test_x=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test X'));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf42efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0af12dd048443ff9a0166923bea99c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Test X', max=3.0, min=-3.0), FloatSlider(value=0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "class_0 = np.random.randn(10, 2) - 1\n",
    "class_1 = np.random.randn(10, 2) + 1\n",
    "\n",
    "X = np.vstack((class_0, class_1))\n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "# Scale features for better convergence\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Logistic Regression via SGD (for custom training steps)\n",
    "model = SGDClassifier(loss=\"log_loss\", max_iter=1, learning_rate='constant', eta0=0.1,\n",
    "                      warm_start=True, random_state=42, tol=None)\n",
    "\n",
    "# Simulate training epoch by epoch and track loss\n",
    "loss_history = []\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    model.partial_fit(X_scaled, y, classes=np.array([0, 1]))\n",
    "    y_proba = model.predict_proba(X_scaled)\n",
    "    log_loss = -np.mean(y * np.log(y_proba[:, 1] + 1e-15) + (1 - y) * np.log(1 - y_proba[:, 1] + 1e-15))\n",
    "    loss_history.append(log_loss)\n",
    "\n",
    "# Interactive plot\n",
    "def plot_logistic_regression(test_x, test_y):\n",
    "    test_point = scaler.transform([[test_x, test_y]])\n",
    "    proba = model.predict_proba(test_point)[0]\n",
    "    pred = model.predict(test_point)[0]\n",
    "\n",
    "    # Decision boundary grid\n",
    "    x_min, x_max = -4, 4\n",
    "    y_min, y_max = -4, 4\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_scaled = scaler.transform(grid)\n",
    "    Z = model.predict(grid_scaled).reshape(xx.shape)\n",
    "\n",
    "    # Plot 1: decision boundaries\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
    "    plt.scatter(class_0[:, 0], class_0[:, 1], color='blue', label='Class 0')\n",
    "    plt.scatter(class_1[:, 0], class_1[:, 1], color='green', label='Class 1')\n",
    "    plt.scatter(test_x, test_y, color='blue' if pred == 0 else 'green',\n",
    "                edgecolor='black', s=200, label=f'Test Point (P1={proba[1]:.2f})')\n",
    "\n",
    "    plt.title(f\"Logistic Regression Decision Boundary — Predicted Class: {pred}\")\n",
    "    plt.xlabel(\"X1\")\n",
    "    plt.ylabel(\"X2\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot 2: loss curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), loss_history, marker='o')\n",
    "    plt.title(\"Logistic Regression Log-Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "interact(plot_logistic_regression,\n",
    "         test_x=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test X'),\n",
    "         test_y=FloatSlider(min=-3, max=3, step=0.1, value=0, description='Test Y'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2045434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
